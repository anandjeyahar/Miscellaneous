1-1 Integer Multiplication:
    --primitive operation -- multiplying two one-digit numbers
    What are the no.of basic operations as afunction of length of input numbers
    -- for a numbers with 'n' digits and 'm' digits, we do atleast nxm multiplication of 1-digit numbers
    -- On top of that we do some additions (atleast min(n,m), but more than that), however it is negligible on algorithm performance at sufficiently big n, and m.
    -- so O(nxm) is the time/operations complexity.
    --  I don't get how he comes up with the max/upper limit of 2n operatios for each row..(total m/n rows).
    -- but as a result he comes up with O(2n**2) operations.


1-2 KaratSuba Multiplication:
    -- Derives from the Recursive algorithm below..
    -- Simplifies/ reduces 4 recursive calls to 3 by reducing a*d + b*c..
    -- Simple algebraic reduction gives (a+b)*(c+d) to ad+ ac + bc + bd
    -- Since we already find a*c and b*d, only need to do the above recursive call and subtract rest.
    -- ergo we have the karatsuba algorithm..

    -- Complexity?? well 4 digit numbers give 3 in the first step each of the three leading to 2 more.
    -- So factorial(n) ?? let's find out from the video..
    --

1-2-1 Recursive approach to Integer multiplication.
    -- Write X=10** n/2 *a + b  and y = 10**n/2 *c + d
    -- a,b,c, and d are n/2 digit numbers.(n-being the no.of digits in each number).
    -- x.y == 10**n*a*c + 10**n/2*(a*d + b*c) + b*d
    -- Recursively split a,b,c,d to smaller digit numbers (stopping at 1-digit numbers) and calculate value
    --- base case being single digit multiplications
    -- complexity? well the recursion means, something like log(n)?(base 2 of course)
    -- and the rest of the multiplications? well 4 digit numbers yield 3 terms first step and then each of the 3 yield 3 so log(n)**log(n)
    -- Is that about right?? let's find out..
1-4 Motivations for the course:
    -- Vocabulary for design and analysis of algorithms(and hopefully correctness proofs?)
    -- Divide and Conquer Programming paradigm(other paradigm covered in 201)
            -- applied in Integer Multiplication, sorting, matrix multiplication, closest pair
            -- General analysis methods, Master method/ theorem
    -- Randomization in algorithm design
            -- quick sort, primality testing, graph partitioning, hashing
            --
    -- Primitives for reasoning about graphs
            -- connectivity information, shortest paths, structure of information, and social networks.
    -- Use and implementation of data structures
            -- Heaps, balanced binary search trees, hashing and some variants(like bloom filters)
            --
    -- Next course concepts:
            --  Greedy algorithm design paradigm (minimal spanning trees, scheduling, information theory)
            --  Dynamic programming algorithms(applications in genomic sequences, shortest path for communication networks)
    -- NP-complete problems
    -- Fast and exact algorithms for special cases
    -- Exact algorithms that improve brute-forec approach


